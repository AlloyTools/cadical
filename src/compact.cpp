#include "internal.hpp"

namespace CaDiCaL {

/*------------------------------------------------------------------------*/

// Compacting removes holes generated by inactive variables (fixed,
// eliminated, substituted or pure) by mapping active variables indices down
// to a contiguous interval of indices.

/*------------------------------------------------------------------------*/

bool Internal::compacting () {
  if (level) return false;
  if (!opts.simplify) return false;
  if (!opts.compact) return false;
  if (stats.conflicts < lim.compact) return false;
  int inactive = max_var - active ();
  assert (inactive >= 0);
  if (!inactive) return false;
  if (inactive < opts.compactmin) return false;
  return inactive >= (1e-3 * opts.compactlim) * max_var;
}

/*------------------------------------------------------------------------*/

// Map old internal literal 'SRC' to new internal literal 'DST'.  This would
// be trivially just a look-up into the 'map' created in 'compact' (caring
// about signedness of 'SRC' though), except that fixed variables have all
// to be mapped to the first fixed variable 'first_fixed', which makes it
// more tricky.
//
#define MAP_LIT(SRC,DST) \
do { \
  int OLD = (SRC); \
  assert (OLD), assert (abs (OLD) <= max_var); \
  int RES = map[abs (OLD)]; \
  if (!RES) { \
    assert (!level); \
    assert (vals_not_mapped_yet); \
    const int TMP = val (OLD); \
    if (TMP) { \
      assert (first_fixed); \
      RES = map_first_fixed; \
      if (TMP != first_fixed_val) RES = -RES; \
    } \
  } else if ((OLD) < 0) RES = -RES; \
  assert (abs (RES) <= new_max_var); \
  (DST) = RES; \
} while (0)

// Map the positive variable indices in array 'NAME' of element type 'TYPE'.
//
#define MAP_ARRAY_ONLY(TYPE,NAME) \
do { \
  for (int SRC = 1; SRC <= max_var; SRC++) { \
    const int DST = map[SRC]; \
    if (!DST) continue; \
    assert (0 < DST), assert (DST <= SRC); \
    assert (DST > 0); \
    NAME[DST] = NAME[SRC]; \
  } \
  SHRINK_ONLY (NAME, TYPE, vsize, new_vsize); \
  PRINT ("mapped '" # NAME "'"); \
} while (0)

// Same as 'MAP_ARRAY_ONLY' but two sided (positive and negative literal).
//
// We need two versions here, one for arrays of 'std::vector' which need
// proper initialization and release operations and then another one which
// does not initialize anything.
//
// This is the first version for arrays containing objects with destructor
// (e.g., in our case only 'std::vector').
//
#define RELEASE_MAP2_ARRAY(TYPE,NAME) \
do { \
  for (int SRC = 1; SRC <= max_var; SRC++) { \
    const int DST = map[SRC]; \
    if (!DST) continue; \
    assert (0 < DST), assert (DST <= SRC); \
    NAME[2*DST] = NAME[2*SRC]; \
    NAME[2*DST+1] = NAME[2*SRC+1]; \
  } \
  RELEASE_SHRINK (NAME, TYPE, 2*vsize, 2*new_vsize); \
  PRINT ("mapped '" # NAME "' (after release)"); \
} while (0)

// This is second version for arrays containing objects which do not have a
// destructor (such as 'noccs2'). The only difference to the previous
// 'RELEASE_MAP2_ARRAY' is to use 'SHRINK_ONLY' without 'RELEASE_SHRINK'.
//
#define MAP2_ARRAY_ONLY(TYPE,NAME) \
do { \
  for (int SRC = 1; SRC <= max_var; SRC++) { \
    const int DST = map[SRC]; \
    if (!DST) continue; \
    assert (0 < DST), assert (DST <= SRC); \
    NAME[2*DST] = NAME[2*SRC]; \
    NAME[2*DST+1] = NAME[2*SRC+1]; \
  } \
  SHRINK_ONLY (NAME, TYPE, 2*vsize, 2*new_vsize); \
  PRINT ("mapped '" # NAME "' (no release)"); \
} while (0)

// Map a 'vector<int>' of literals, flush inactive literals, resize and
// shrink it to fit its new size after flushing.
//
#define MAP_FLUSH_AND_SHRINK_INT_VECTOR(V) \
do { \
  const auto end = V.end (); \
  auto j = V.begin (), i = j; \
  for (; i != end; i++) { \
    const int SRC = *i; \
    int DST = map[abs (SRC)]; \
    assert (abs (DST) <= abs (SRC)); \
    if (!DST) continue; \
    if (SRC < 0) DST = -DST; \
    *j++ = DST; \
  } \
  V.resize (j - V.begin ()); \
  shrink_vector (V); \
  PRINT ("mapped '" # V "'"); \
} while (0)

/*------------------------------------------------------------------------*/

#ifndef QUIET

#ifdef LOGGING
#define PRINTVERBOSEGUARD !opts.log
#else
#define PRINTVERBOSEGUARD true
#endif

#define PRINT(MSG) \
do { \
  if (opts.quiet) break; \
  if (PRINTVERBOSEGUARD && opts.verbose < 2) break; \
  print_prefix (); \
  printf ("[compact-%ld] %s %.0f MB\n", stats.compacts, \
    (MSG), current_resident_set_size ()/(double)(1<<20) ); \
  fflush (stdout); \
} while (0)

#else
#define PRINT(MSG) do { } while (0)
#endif

/*------------------------------------------------------------------------*/

void Internal::compact () {

  PRINT ("BEFORE");

  START (compact);

  assert (active () < max_var);

  stats.compacts++;

  assert (!level);
  assert (!unsat);
  assert (!conflict);
  assert (clause.empty ());
  assert (levels.empty ());
  assert (analyzed.empty ());
  assert (minimized.empty ());
  assert (control.size () == 1);
  assert (propagated == trail.size ());

  garbage_collection ();

  /*----------------------------------------------------------------------*/
  // We produce a compacting garbage collector like map of old 'src' to
  // new 'dst' variables.  Inactive variables are just skipped except for
  // fixed ones which will be mapped to the first fixed variable (in the
  // appropriate phase).  This avoids to handle the case 'fixed value'
  // separately as it is done in Lingeling, where fixed variables are
  // mapped to the internal variable '1'.
  //
  int * map, new_max_var = 0, first_fixed = 0, map_first_fixed = 0;
  NEW_ZERO (map, int, max_var + 1);
  for (int src = 1; src <= max_var; src++) {
    const Flags & f = flags (src);
    if (f.active ()) map[src] = ++new_max_var;
    else if (f.fixed () && !first_fixed)
      map[first_fixed = src] = map_first_fixed = ++new_max_var;
  }
#ifndef NDEBUG
  bool vals_not_mapped_yet = true;      // for testing & debugging
#endif
  const int first_fixed_val = first_fixed ? val (first_fixed) : 0;

  if (first_fixed)
    LOG ("found first fixed %d", sign (first_fixed_val)*first_fixed);
  else LOG ("no variable fixed");

  const size_t new_vsize = new_max_var + 1;  // Adjust to fit 'new_max_var'.

  PRINT ("generated 'map'");

  if (!assumptions.empty ()) {
    assert (!external->assumptions.empty ());
    LOG ("temporarily reset internal assumptions");
    reset_assumptions ();
  }

  /*----------------------------------------------------------------------*/
  // In this first part we only map stuff without reallocation.
  /*----------------------------------------------------------------------*/

  // Flush the external indices.  This has to occur before we map 'vals'.
  //
  for (int eidx = 1; eidx <= external->max_var; eidx++) {
    int src = external->e2i[eidx], dst;
    if (!src) continue;
    MAP_LIT (src, dst);
    LOG ("compact %ld maps external %d to internal %d from internal %d",
      stats.compacts, eidx, dst, src);
    external->e2i[eidx] = dst;
  }

  PRINT ("mapped 'i2e'");

  // Map the literals in all clauses.
  //
  for (const auto & c : clauses) {
    assert (!c->garbage);
    for (auto & src : *c) {
      assert (!val (src));
      int dst;
      MAP_LIT (src, dst);
      assert (dst || c->garbage);
      src = dst;
    }
  }

  PRINT ("mapped 'clauses'");

  // Map the blocking literals in all watches.
  //
  if (watches ())
    for (int idx = 1; idx <= max_var; idx++)
      for (int sign = -1; sign <= 1; sign += 2)
        for (auto & w : watches (sign*idx))
          MAP_LIT (w.blit, w.blit);

  PRINT ("mapped 'blits'");

  // We first flush inactive variables and map the links in the queue.  This
  // has to be done before we map the actual links data structure 'ltab'.
  {
    int prev = 0, mapped_prev = 0, next;
    for (int idx = queue.first; idx; idx = next) {
      Link * l = ltab + idx;
      next = l->next;
      if (idx == first_fixed) continue;
      const int dst = map[idx];
      if (!dst) continue;
      assert (active (idx));
      if (prev) ltab[prev].next = dst; else queue.first = dst;
      l->prev = mapped_prev;
      mapped_prev = dst;
      prev = idx;
    }
    if (prev) ltab[prev].next = 0; else queue.first = 0;
    queue.unassigned = queue.last = mapped_prev;
  }

  PRINT ("mapped 'queue'");

  /*----------------------------------------------------------------------*/
  // In the second part we map, flush and shrink arrays.
  /*----------------------------------------------------------------------*/

  MAP_FLUSH_AND_SHRINK_INT_VECTOR (trail);
  propagated = trail.size ();
  if (first_fixed) {
    assert (trail.size () == 1);
    var (first_fixed).trail = 0;                // before mapping 'vtab'
  } else assert (trail.empty ());

  if (!probes.empty ()) MAP_FLUSH_AND_SHRINK_INT_VECTOR (probes);

  /*----------------------------------------------------------------------*/
  // In the third part we map stuff and also reallocate memory.
  /*----------------------------------------------------------------------*/

  // Now we continue in reverse order of allocated bytes, e.g., see
  // 'Internal::enlarge' which reallocates in order of allocated bytes.

  MAP_ARRAY_ONLY (Flags, ftab);
  MAP_ARRAY_ONLY (signed_char, marks);
  MAP_ARRAY_ONLY (Phase, phases.saved);
  MAP_ARRAY_ONLY (Phase, phases.target);
  MAP_ARRAY_ONLY (Phase, phases.best);
  MAP_ARRAY_ONLY (Phase, phases.prev);
  MAP_ARRAY_ONLY (Phase, phases.min);

  // Special code for 'frozentab'.
  //
  {
    unsigned * new_frozentab;
    NEW_ZERO  (new_frozentab, unsigned, new_vsize);
    for (int src = 1; src <= max_var; src++)
      new_frozentab[map[src]] += frozentab[src];        // accumulate!
    DELETE_ONLY (frozentab, unsigned, vsize);
    frozentab = new_frozentab;
  }

  PRINT ("mapped 'frozentab'");

  if (!external->assumptions.empty ()) {

    for (const auto & elit : external->assumptions) {
      assert (elit);
      assert (elit != INT_MIN);
      int eidx = abs (elit);
      assert (eidx <= external->max_var);
      int ilit = external->e2i[eidx];
      assert (ilit);            // Because we froze all!!!
      if (elit < 0) ilit = -ilit;
      assume (ilit);
    }

    PHASE ("compact", stats.compacts,
      "reassumed %zd external assumptions",
      external->assumptions.size ());
  }

  // Special case for 'val' as for 'val' we trade branch less code for
  // memory and always allocated an [-maxvar,...,maxvar] array.
  {
#ifndef NDEBUG
    vals_not_mapped_yet = false;        // for testing & debugging
#endif
    signed_char * new_vals;
    NEW_ONLY (new_vals, signed_char, 2*new_vsize);
    new_vals += new_vsize;
    for (int src = -max_var; src <= -1; src++)
      new_vals[-map[-src]] = vals[src];
    for (int src = 1; src <= max_var; src++)
      new_vals[map[src]] = vals[src];
    new_vals[0] = 0;
    vals -= vsize;
    DELETE_ONLY (vals, signed_char, 2*vsize);
    vals = new_vals;
  }

  PRINT ("mapped 'vals'");

  MAP_ARRAY_ONLY (int, i2e);
  MAP2_ARRAY_ONLY (int, ptab);
  MAP_ARRAY_ONLY (long, btab);
  MAP_ARRAY_ONLY (Link, ltab);
  MAP_ARRAY_ONLY (Var, vtab);
  if (ntab) MAP2_ARRAY_ONLY (long, ntab);
  if (ntab2) MAP_ARRAY_ONLY (long, ntab2);
  if (wtab) RELEASE_MAP2_ARRAY (Watches, wtab);
  if (otab) RELEASE_MAP2_ARRAY (Occs, otab);
  if (big) RELEASE_MAP2_ARRAY (Bins, big);

  /*----------------------------------------------------------------------*/
  // In the fourth part we map the binary heap for scores.
  /*----------------------------------------------------------------------*/

  // The simplest way to map a binary heap is to get all elements from the
  // heap and reinsert them.  This could be slightly improved in terms of
  // speed if we add a 'flush (int * map)' function to 'Heap', but that is
  // pretty complicated and would require that the 'Heap' knows that mapped
  // elements with 'zero' destination should be flushed.

  vector<int> saved;
  assert (saved.empty ());
  if (!scores.empty ()) {
    while (!scores.empty ()) {
      const int src = scores.front ();
      scores.pop_front ();
      const int dst = map [src];
      if (dst && src != first_fixed) saved.push_back (dst);
    }
    scores.erase ();
  }
  MAP_ARRAY_ONLY (double, stab);
  if (!saved.empty ()) {
    for (const auto & idx : saved)
      scores.push_back (idx);
    scores.shrink ();
  }
  PRINT ("mapped 'scores'");

  /*----------------------------------------------------------------------*/

  DELETE_ONLY (map, int, max_var);

  PHASE ("compact", stats.compacts,
    "reducing internal variables from %d to %d",
    max_var, new_max_var);

  /*----------------------------------------------------------------------*/

  // Need to adjust the target and best assigned counters too.

  size_t new_target_assigned = 0, new_best_assigned = 0;

  for (int idx = 1; idx <= new_max_var; idx++) {
    if (phases.target[idx]) new_target_assigned++;
    if (phases.best[idx]) new_best_assigned++;
  }

  LOG ("reset target assigned from %zd to %zd",
    target_assigned, new_target_assigned);
  LOG ("reset best assigned from %zd to %zd",
    best_assigned, new_best_assigned);

  target_assigned = new_target_assigned;
  best_assigned = new_best_assigned;
  no_conflict_until = 0;

  INIT_EMA (averages.current.trail.fast, opts.ematrailfast);
  INIT_EMA (averages.current.trail.slow, opts.ematrailslow);

  /*----------------------------------------------------------------------*/

  max_var = new_max_var;
  vsize = new_vsize;

  stats.unused = 0;
  stats.inactive = stats.now.fixed = first_fixed ? 1 : 0;
  stats.now.substituted = stats.now.eliminated = stats.now.pure = 0;

  check_var_stats ();

  long delta = opts.compactint * (stats.compacts + 1);
  lim.compact = stats.conflicts + delta;

  PHASE ("compact", stats.compacts,
    "new compact limit %ld after %ld conflicts",
    lim.compact, delta);

  report ('/');
  STOP (compact);

  PRINT ("AFTER");
}

}
